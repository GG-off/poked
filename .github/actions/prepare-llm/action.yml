name: Prepare TinyLlama
description: Download TinyLlama and launch it
runs:
  using: "composite"
  steps:
    - name: Download TinyLlama model
      shell: bash
      run: curl -OL https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf

    - name: Download and unpack Nitro
      shell: bash
      run: |
        curl -OL https://github.com/janhq/nitro/releases/download/v0.3.14/nitro-0.3.14-linux-amd64.tar.gz
        tar zxvf nitro-0.3.14-linux-amd64.tar.gz

    - name: Launch Nitro
      shell: bash
      run: ./nitro/nitro 2 127.0.0.1 8080 &

    - name: Wait until Nitro is ready
      shell: bash
      run: while ! curl -s 'http://localhost:8080/healthz' | grep 'alive'; do sleep 1; done

    - name: Load TinyLlama into Nitro
      shell: bash
      run: |
        curl http://localhost:8080/inferences/llamacpp/loadmodel \
          -H 'Content-Type: application/json' \
          -d '{"llama_model_path": "./tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf"}'
